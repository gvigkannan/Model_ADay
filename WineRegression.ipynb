{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WineRegression.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "JvBC-5OUvQFP"
      ],
      "authorship_tag": "ABX9TyMNK+Xo5RoLMx63a+zb98Ta",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4326d87617054a2bb0f8752371b65e0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a31306f8e12f4dd095096516e42917cb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f5f220158b2c4a6b9b96987e6207551d",
              "IPY_MODEL_f5d398181f6f441aafe826cb84a012a5"
            ]
          }
        },
        "a31306f8e12f4dd095096516e42917cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f5f220158b2c4a6b9b96987e6207551d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4ed207055182460296f942157803da96",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 150,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 150,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_94bfb3f3c4c14290a94964696f29f20e"
          }
        },
        "f5d398181f6f441aafe826cb84a012a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7d5092464c674b6db9860b83eb7235eb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 150/150 [00:48&lt;00:00,  3.10it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_80eeefd1fda742e2bb6cf82d30dd597e"
          }
        },
        "4ed207055182460296f942157803da96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "94bfb3f3c4c14290a94964696f29f20e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7d5092464c674b6db9860b83eb7235eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "80eeefd1fda742e2bb6cf82d30dd597e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gvigkannan/Model_ADay/blob/Keras/WineRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38M00mVUrXPh"
      },
      "source": [
        "## Sample Regression Notebook\n",
        "## Adapted from: https://towardsdatascience.com/pytorch-tabular-regression-428e9c9ac93\n",
        "## By Vignesh Kannan"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvBC-5OUvQFP"
      },
      "source": [
        "## Loading Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3RSz3_fvNm1"
      },
      "source": [
        "## Standard Library:\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "import copy"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1s8TuzzevhdZ"
      },
      "source": [
        "## Torch Related\n",
        "import torch, torchvision, torchsummary\n",
        "import torch.nn as nn \n",
        "import torch.optim as optim \n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7ERHFhDzQ9W"
      },
      "source": [
        "## Sklearn\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score"
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wi7kfUuBCgy-"
      },
      "source": [
        "## Hyperparams!\n",
        "EPOCHS = 150\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 0.001\n"
      ],
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlgyV3cuzh4-"
      },
      "source": [
        "## Reading and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGSAQAY1y_kO",
        "outputId": "e3eb7584-8fa5-4656-e6dc-8fc539ee5acc"
      },
      "source": [
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\n"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-17 00:24:52--  https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84199 (82K) [application/x-httpd-php]\n",
            "Saving to: â€˜winequality-red.csv.6â€™\n",
            "\n",
            "winequality-red.csv 100%[===================>]  82.23K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-04-17 00:24:52 (780 KB/s) - â€˜winequality-red.csv.6â€™ saved [84199/84199]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "Z8lNzp0wzKY8",
        "outputId": "be98557b-0dcb-4c09-b9eb-f1ee7e125be1"
      },
      "source": [
        "df = pd.read_csv(\"/content/winequality-red.csv\", sep = ';')\n",
        "df.head()"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.098</td>\n",
              "      <td>25.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.9968</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.68</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.092</td>\n",
              "      <td>15.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.9970</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.65</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.2</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.075</td>\n",
              "      <td>17.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.9980</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.58</td>\n",
              "      <td>9.8</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fixed acidity  volatile acidity  citric acid  ...  sulphates  alcohol  quality\n",
              "0            7.4              0.70         0.00  ...       0.56      9.4        5\n",
              "1            7.8              0.88         0.00  ...       0.68      9.8        5\n",
              "2            7.8              0.76         0.04  ...       0.65      9.8        5\n",
              "3           11.2              0.28         0.56  ...       0.58      9.8        6\n",
              "4            7.4              0.70         0.00  ...       0.56      9.4        5\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaTmXrvCzuKv"
      },
      "source": [
        "X = df.drop(columns = 'quality')\n",
        "y = df['quality']\n",
        "\n",
        "## Splitting into train, val, test\n",
        "trainX, testX, trainY, testY = train_test_split(X, y, test_size = 0.2, stratify = y, random_state = 42)\n",
        "trainX, valX, trainY, valY = train_test_split(trainX, trainY, test_size = 0.2, stratify = trainY, random_state = 42)\n",
        "\n",
        "## Normalizing Data\n",
        "scaler = MinMaxScaler()\n",
        "trainX = scaler.fit_transform(trainX)\n",
        "valX = scaler.transform(valX)\n",
        "testX = scaler.transform(testX)\n",
        "\n",
        "trainX, trainY = np.array(trainX), np.array(trainY).astype(float)\n",
        "testX, testY = np.array(testX), np.array(testY).astype(float)\n",
        "valX, valY = np.array(valX), np.array(valY).astype(float)"
      ],
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcP_Q6_z0hX-"
      },
      "source": [
        "def get_class_distribution(obj):\n",
        "    count_dict = {\n",
        "        \"rating_3\": 0,\n",
        "        \"rating_4\": 0,\n",
        "        \"rating_5\": 0,\n",
        "        \"rating_6\": 0,\n",
        "        \"rating_7\": 0,\n",
        "        \"rating_8\": 0,\n",
        "    }\n",
        "    \n",
        "    for i in obj:\n",
        "        if i == 3: \n",
        "            count_dict['rating_3'] += 1\n",
        "        elif i == 4: \n",
        "            count_dict['rating_4'] += 1\n",
        "        elif i == 5: \n",
        "            count_dict['rating_5'] += 1\n",
        "        elif i == 6: \n",
        "            count_dict['rating_6'] += 1\n",
        "        elif i == 7: \n",
        "            count_dict['rating_7'] += 1  \n",
        "        elif i == 8: \n",
        "            count_dict['rating_8'] += 1              \n",
        "        else:\n",
        "            print(\"Check classes.\")\n",
        "            \n",
        "    return count_dict"
      ],
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJ0VSz_tBBMi"
      },
      "source": [
        "## Initializing the dataset\n",
        "class RegressionDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataX, dataY):\n",
        "      self.dataX = dataX\n",
        "      self.dataY = dataY\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "      return self.dataX[index], self.dataY[index]\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.dataX)\n"
      ],
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0e9b9d5uBlIx"
      },
      "source": [
        "train_dataset = RegressionDataset(torch.from_numpy(trainX).float(), \n",
        "                                  torch.from_numpy(trainY).float())\n",
        "\n",
        "test_dataset = RegressionDataset(torch.from_numpy(testX).float(), \n",
        "                                  torch.from_numpy(testY).float())\n",
        "\n",
        "val_dataset = RegressionDataset(torch.from_numpy(valX).float(), \n",
        "                                  torch.from_numpy(valY).float())\n",
        "\n"
      ],
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peqnV0viD1uq"
      },
      "source": [
        "NUM_FEATURES = len(X.columns)"
      ],
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uc3Q_D1SB8Wk"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yhdhty7CF7h"
      },
      "source": [
        "## Initialize Dataloader:\n",
        "train_dl = DataLoader(dataset = train_dataset, \n",
        "                      batch_size = BATCH_SIZE, \n",
        "                      shuffle = True)\n",
        "\n",
        "test_dl = DataLoader(dataset = test_dataset,\n",
        "                     batch_size = 1)\n",
        "\n",
        "val_dl = DataLoader(dataset = val_dataset,\n",
        "                     batch_size = 1)"
      ],
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rzuTG8RLHCF",
        "outputId": "de91f661-9e54-4990-da9b-37969bc26ea0"
      },
      "source": [
        "torch.from_numpy(trainX).float()"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3274, 0.5714, 0.2900,  ..., 0.6121, 0.1801, 0.4769],\n",
              "        [0.5841, 0.4911, 0.5500,  ..., 0.3707, 0.1988, 0.1692],\n",
              "        [0.3274, 0.8036, 0.0200,  ..., 0.6379, 0.0621, 0.4000],\n",
              "        ...,\n",
              "        [0.4956, 0.2589, 0.4300,  ..., 0.3621, 0.1739, 0.3692],\n",
              "        [0.5929, 0.4464, 0.6700,  ..., 0.4138, 0.1863, 0.7692],\n",
              "        [0.2124, 0.3750, 0.0000,  ..., 0.5603, 0.2795, 0.4615]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDAXVbl2LCO2",
        "outputId": "2588a2a6-d8b0-4171-9c57-6479665105d5"
      },
      "source": [
        "next(iter(train_dl))"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[0.3363, 0.2232, 0.4300, 0.0966, 0.0851, 0.1642, 0.0426, 0.3987, 0.3707,\n",
              "          0.2609, 0.4308],\n",
              "         [0.2832, 0.6250, 0.2900, 0.2345, 0.1185, 0.2985, 0.2021, 0.4662, 0.3621,\n",
              "          0.0870, 0.1538],\n",
              "         [0.1770, 0.2411, 0.4900, 0.0552, 0.0968, 0.3284, 0.5035, 0.1564, 0.3276,\n",
              "          0.0683, 0.4769],\n",
              "         [0.3894, 0.5089, 0.0000, 0.1034, 0.1269, 0.2687, 0.1099, 0.6557, 0.5259,\n",
              "          0.1304, 0.1385],\n",
              "         [0.3717, 0.4286, 0.2900, 0.0897, 0.1436, 0.0597, 0.0284, 0.6410, 0.5345,\n",
              "          0.0621, 0.1077],\n",
              "         [0.4336, 0.4018, 0.2700, 0.0966, 0.1169, 0.3284, 0.4858, 0.5690, 0.4569,\n",
              "          0.0994, 0.1538],\n",
              "         [0.2212, 0.6741, 0.0500, 0.3310, 0.1169, 0.0299, 0.0248, 0.5881, 0.5690,\n",
              "          0.0807, 0.2769],\n",
              "         [0.2478, 0.5938, 0.1900, 0.2966, 0.1369, 0.2687, 0.3227, 0.5184, 0.3621,\n",
              "          0.0807, 0.1846],\n",
              "         [0.6283, 0.1429, 0.4700, 0.0552, 0.0701, 0.2388, 0.0887, 0.4985, 0.3534,\n",
              "          0.1739, 0.3385],\n",
              "         [0.2124, 0.4732, 0.0200, 0.0828, 0.0902, 0.1045, 0.0638, 0.5235, 0.6293,\n",
              "          0.1739, 0.1692],\n",
              "         [0.1947, 0.3125, 0.0800, 0.0897, 0.0868, 0.2537, 0.1099, 0.4009, 0.4828,\n",
              "          0.1615, 0.1846],\n",
              "         [0.2389, 0.2857, 0.2000, 0.0483, 0.0618, 0.3433, 0.2021, 0.2518, 0.5517,\n",
              "          0.1118, 0.5077],\n",
              "         [0.4513, 0.1696, 0.4700, 0.0483, 0.0835, 0.1791, 0.0922, 0.6043, 0.4569,\n",
              "          0.1677, 0.2462],\n",
              "         [0.6549, 0.2946, 0.5500, 0.0759, 0.1018, 0.3582, 0.1489, 0.7070, 0.3103,\n",
              "          0.2298, 0.2923],\n",
              "         [0.2478, 0.2143, 0.2900, 0.1172, 0.1252, 0.3731, 0.2305, 0.4684, 0.5603,\n",
              "          0.1801, 0.4000],\n",
              "         [0.4867, 0.1696, 0.3500, 0.0483, 0.1052, 0.1194, 0.0745, 0.4883, 0.4310,\n",
              "          0.2733, 0.4308],\n",
              "         [0.3894, 0.3750, 0.4900, 0.1379, 0.1369, 0.5970, 0.3652, 0.5969, 0.2931,\n",
              "          0.1366, 0.1231],\n",
              "         [0.5575, 0.2411, 0.4700, 0.0621, 0.1770, 0.0746, 0.0248, 0.5969, 0.4828,\n",
              "          0.2236, 0.2154],\n",
              "         [0.3009, 0.4911, 0.3000, 0.0759, 0.0801, 0.5522, 0.1950, 0.4207, 0.4483,\n",
              "          0.1056, 0.2769],\n",
              "         [0.2212, 0.5089, 0.0400, 0.0828, 0.0935, 0.2687, 0.0709, 0.5176, 0.6034,\n",
              "          0.1739, 0.2154],\n",
              "         [0.3451, 0.3304, 0.1100, 0.0966, 0.1202, 0.1194, 0.2128, 0.4941, 0.3707,\n",
              "          0.0870, 0.1538],\n",
              "         [0.1947, 0.4732, 0.0200, 0.0828, 0.1102, 0.1045, 0.0284, 0.3605, 0.5259,\n",
              "          0.1429, 0.3077],\n",
              "         [0.5664, 0.1607, 0.5800, 0.0828, 0.0701, 0.0896, 0.0426, 0.5822, 0.4914,\n",
              "          0.3043, 0.3231],\n",
              "         [0.2655, 0.2768, 0.2900, 0.0828, 0.1052, 0.2687, 0.2092, 0.5220, 0.5690,\n",
              "          0.1553, 0.1692],\n",
              "         [0.5487, 0.1250, 0.4500, 0.1655, 0.0801, 0.2836, 0.1489, 0.5235, 0.3362,\n",
              "          0.0932, 0.1846],\n",
              "         [0.4425, 0.4286, 0.5000, 0.0966, 0.1119, 0.4030, 0.2270, 0.7070, 0.6552,\n",
              "          0.1118, 0.2000],\n",
              "         [0.1593, 0.4018, 0.1200, 0.0966, 0.1803, 0.3582, 0.1028, 0.3759, 0.6293,\n",
              "          0.1988, 0.4462],\n",
              "         [0.2035, 0.6429, 0.2100, 0.2207, 0.1035, 0.2239, 0.2057, 0.6131, 0.6810,\n",
              "          0.2050, 0.1308],\n",
              "         [0.2920, 0.2768, 0.2100, 0.0483, 0.1569, 0.1343, 0.1064, 0.4794, 0.3707,\n",
              "          0.3230, 0.1692],\n",
              "         [0.3894, 0.4821, 0.1700, 0.1448, 0.1085, 0.0597, 0.0213, 0.5529, 0.4741,\n",
              "          0.0994, 0.3077],\n",
              "         [0.5575, 0.2411, 0.4700, 0.0621, 0.1770, 0.0746, 0.0248, 0.5969, 0.4828,\n",
              "          0.2236, 0.2154],\n",
              "         [0.4071, 0.2768, 0.4900, 0.1034, 0.1235, 0.3284, 0.3865, 0.5529, 0.4224,\n",
              "          0.1553, 0.1692]]),\n",
              " tensor([7., 5., 6., 5., 5., 5., 3., 6., 7., 6., 6., 6., 6., 6., 5., 7., 5., 6.,\n",
              "         6., 5., 5., 6., 7., 5., 5., 5., 7., 6., 5., 5., 6., 5.])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_ooACocCcKT"
      },
      "source": [
        "## Model Related"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHO92hmUCW9-"
      },
      "source": [
        "class RegressionModel(nn.Module):\n",
        "  def __init__(self, num_features):\n",
        "    super(RegressionModel, self).__init__()\n",
        "\n",
        "    self.layer1 = nn.Linear(num_features, 16)\n",
        "    self.layer2 = nn.Linear(16, 32)\n",
        "    self.layer3 = nn.Linear(32, 16)\n",
        "    self.out = nn.Linear(16, 1)\n",
        "\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    x = self.relu(self.layer1(inputs))\n",
        "    x = self.relu(self.layer2(x))\n",
        "    x = self.relu(self.layer3(x))\n",
        "    x = self.out(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "  def predict(self, inputs):\n",
        "    x = self.relu(self.layer1(inputs))\n",
        "    x = self.relu(self.layer2(x))\n",
        "    x = self.relu(self.layer3(x))\n",
        "    x = self.out(x)     "
      ],
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwBxhtY0DR_G",
        "outputId": "94f44471-0df2-4b31-9f25-8a6e570c4c14"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mCblW90DsKv",
        "outputId": "1b1b1201-5503-4d6e-b606-3315f62636b7"
      },
      "source": [
        "model = RegressionModel(NUM_FEATURES).to(device)\n",
        "print(model)\n",
        "torchsummary.summary(model, (NUM_FEATURES,))"
      ],
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RegressionModel(\n",
            "  (layer1): Linear(in_features=11, out_features=16, bias=True)\n",
            "  (layer2): Linear(in_features=16, out_features=32, bias=True)\n",
            "  (layer3): Linear(in_features=32, out_features=16, bias=True)\n",
            "  (out): Linear(in_features=16, out_features=1, bias=True)\n",
            "  (relu): ReLU()\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                   [-1, 16]             192\n",
            "              ReLU-2                   [-1, 16]               0\n",
            "            Linear-3                   [-1, 32]             544\n",
            "              ReLU-4                   [-1, 32]               0\n",
            "            Linear-5                   [-1, 16]             528\n",
            "              ReLU-6                   [-1, 16]               0\n",
            "            Linear-7                    [-1, 1]              17\n",
            "================================================================\n",
            "Total params: 1,281\n",
            "Trainable params: 1,281\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.00\n",
            "Estimated Total Size (MB): 0.01\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Asy9xAkEAON"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2y2_BQIqDwqi"
      },
      "source": [
        "## Training Related\n",
        "loss_stats = {'train': [], 'val': []}\n"
      ],
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbnxbCzHFu-v"
      },
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model, val_dl, criterion):\n",
        "  \"\"\" \n",
        "  Evaluation Step for Regression Model\n",
        "  Inputs Needed: Model, Validation DataLoader, Loss Criterion\n",
        "  Output: Loss value and Prediction for Validation Data\n",
        "  \"\"\"\n",
        "  model.eval()\n",
        "  loss = 0.0\n",
        "  for X, y in val_dl:\n",
        "    out = model(X)\n",
        "    loss += criterion(out, y.unsqueeze(1))\n",
        "  return loss "
      ],
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfnx-MezG5aJ",
        "outputId": "c7247036-fcc8-4eca-aaf7-9f5e97b4c0d3"
      },
      "source": [
        "len(train_dl)"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ED9fWN--NoCV",
        "outputId": "dcbda6ca-2451-4ff8-f1a2-70b6a6899890"
      },
      "source": [
        "len(val_dl)"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTWIswbAEXJU"
      },
      "source": [
        "def fit(model, criterion, optimizer, train_dl, val_dl, numEpochs):\n",
        "  \"\"\"Fit Train Data and evaluate for Validation Data\"\"\"\n",
        "  start_fit = time()\n",
        "  best_vloss = np.inf\n",
        "  best_WandB = copy.deepcopy(model.state_dict())\n",
        "\n",
        "  ## For all epochs:\n",
        "  for epoch in tqdm(range(numEpochs)):\n",
        "    print(\"Epoch: {}\".format(epoch+1))\n",
        "    flag_new = False\n",
        "    print(\"*\"*15)\n",
        "    epoch_time = time()\n",
        "    ## Training\n",
        "    train_epoch_loss = 0.0\n",
        "    model.train()\n",
        "\n",
        "    for X, y in train_dl:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      optimizer.zero_grad() ## Reset the residual gradients\n",
        "      \n",
        "      ## Forward\n",
        "      predY = model(X)\n",
        "      train_loss = criterion(predY, y.unsqueeze(1))\n",
        "      ## Unsqueeze gives a column vector!\n",
        "\n",
        "      train_loss.backward()\n",
        "      optimizer.step()\n",
        "      train_epoch_loss += train_loss.item() / len(y)\n",
        "    \n",
        "    val_loss = evaluate(model, val_dl, criterion).item() / len(val_dl)\n",
        "    loss_stats['train'].append(train_epoch_loss)\n",
        "    loss_stats['val'].append(val_loss)\n",
        "    ## Model Checkpoint\n",
        "    if best_vloss > val_loss:\n",
        "      best_vloss = val_loss\n",
        "      best_WandB = model.state_dict()\n",
        "      flag_new = True\n",
        "\n",
        "    print(\"Train Loss: {:.4f}\\t Valid Loss: {:.4f}\\nTime per Epoch: {:.4f}\".format(train_epoch_loss, val_loss,  time() - epoch_time))\n",
        "    print()\n",
        "    if flag_new:\n",
        "      print(\"\\nNew Best Val Loss Found!\")\n",
        "  if val_loss > best_vloss:\n",
        "      model.load_state_dict(best_WandB)\n",
        "  return model\n"
      ],
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsZRUcG7IjbN"
      },
      "source": [
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), \n",
        "                       lr = LEARNING_RATE)"
      ],
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5YBRBNVK83O",
        "outputId": "e280a5d8-3142-4caf-e64c-ad8cf4941bf2"
      },
      "source": [
        "next(iter(train_dl))"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[0.3805, 0.3393, 0.2100, 0.0897, 0.1269, 0.2985, 0.1135, 0.5029, 0.5086,\n",
              "          0.2733, 0.4154],\n",
              "         [0.3717, 0.2857, 0.4900, 0.1310, 0.1185, 0.2537, 0.3688, 0.5969, 0.4828,\n",
              "          0.1304, 0.1692],\n",
              "         [0.4956, 0.1875, 0.4600, 0.0690, 0.1152, 0.0746, 0.0071, 0.4559, 0.3103,\n",
              "          0.0559, 0.3077],\n",
              "         [0.1327, 0.1786, 0.2500, 0.0966, 0.0985, 0.3284, 0.1809, 0.4596, 0.5862,\n",
              "          0.3602, 0.3385],\n",
              "         [0.2566, 0.2500, 0.1800, 0.0483, 0.1119, 0.3433, 0.1809, 0.4721, 0.5172,\n",
              "          0.1180, 0.1538],\n",
              "         [0.2743, 0.5312, 0.0100, 0.0828, 0.0868, 0.4478, 0.1277, 0.2673, 0.5776,\n",
              "          0.1118, 0.5231],\n",
              "         [0.5487, 0.1786, 0.4400, 0.0483, 0.0851, 0.2239, 0.1064, 0.6189, 0.4138,\n",
              "          0.2422, 0.2462],\n",
              "         [0.3540, 0.4598, 0.6800, 0.0621, 0.6528, 0.2687, 0.1738, 0.4589, 0.2414,\n",
              "          0.4720, 0.1385],\n",
              "         [0.3540, 0.3125, 0.2700, 0.0966, 0.0718, 0.1940, 0.0745, 0.3737, 0.3793,\n",
              "          0.2547, 0.4308],\n",
              "         [0.4159, 0.2500, 0.4900, 0.1103, 0.1219, 0.5522, 0.4787, 0.5675, 0.4138,\n",
              "          0.0994, 0.1538],\n",
              "         [0.2920, 0.1786, 0.5100, 0.0621, 0.5492, 0.2388, 0.1738, 0.5015, 0.2586,\n",
              "          0.4286, 0.1231],\n",
              "         [0.2124, 0.2768, 0.0200, 0.0690, 0.1135, 0.2090, 0.0745, 0.3561, 0.5259,\n",
              "          0.2609, 0.3385],\n",
              "         [0.3186, 0.2411, 0.4900, 0.0966, 0.1452, 0.6866, 0.4468, 0.5749, 0.5517,\n",
              "          0.3727, 0.2154],\n",
              "         [0.2212, 0.5089, 0.0400, 0.0828, 0.0935, 0.2687, 0.0709, 0.5176, 0.6034,\n",
              "          0.1739, 0.2154],\n",
              "         [0.1858, 0.3750, 0.1300, 0.0759, 0.1068, 0.2090, 0.1028, 0.5308, 0.7500,\n",
              "          0.1553, 0.2154],\n",
              "         [0.1239, 0.3304, 0.0000, 0.0966, 0.0935, 0.2090, 0.0922, 0.2093, 0.7241,\n",
              "          0.1242, 0.6308],\n",
              "         [0.3274, 0.4732, 0.1000, 0.1379, 0.1285, 0.2388, 0.1170, 0.5844, 0.4741,\n",
              "          0.0994, 0.1692],\n",
              "         [0.2301, 0.4286, 0.0400, 0.1103, 0.1068, 0.2537, 0.2872, 0.5419, 0.6810,\n",
              "          0.0994, 0.1692],\n",
              "         [0.3274, 0.4286, 0.2500, 0.0897, 0.1770, 0.1194, 0.1099, 0.4471, 0.3534,\n",
              "          0.0870, 0.2154],\n",
              "         [0.4779, 0.5446, 0.4300, 0.0966, 0.0785, 0.2090, 0.0851, 0.4794, 0.3534,\n",
              "          0.1118, 0.4000],\n",
              "         [0.2035, 0.2500, 0.2400, 0.1103, 0.1185, 0.4328, 0.1348, 0.4280, 0.4483,\n",
              "          0.1180, 0.2462],\n",
              "         [0.2212, 0.3036, 0.1400, 0.1310, 0.1068, 0.2090, 0.1064, 0.4530, 0.5345,\n",
              "          0.0621, 0.3538],\n",
              "         [0.2301, 0.2143, 0.4600, 0.0828, 0.1035, 0.3433, 0.1312, 0.3869, 0.5690,\n",
              "          0.2857, 0.4000],\n",
              "         [0.0796, 0.3304, 0.0300, 0.0621, 0.0534, 0.4030, 0.2837, 0.0536, 0.6552,\n",
              "          0.2671, 0.8615],\n",
              "         [0.3009, 0.3214, 0.3400, 0.0897, 0.1018, 0.2239, 0.0638, 0.2592, 0.4655,\n",
              "          0.1677, 0.6154],\n",
              "         [0.3451, 0.2500, 0.4000, 0.3724, 0.0634, 0.0299, 0.0106, 0.4104, 0.4655,\n",
              "          0.1056, 0.5538],\n",
              "         [0.4248, 0.1339, 0.5300, 0.1034, 0.1035, 0.0746, 0.0390, 0.4501, 0.3966,\n",
              "          0.4596, 0.5538],\n",
              "         [0.3186, 0.5893, 0.0000, 0.0897, 0.1285, 0.1791, 0.0674, 0.5675, 0.5431,\n",
              "          0.0435, 0.1846],\n",
              "         [0.1947, 0.7054, 0.0600, 0.0759, 0.0801, 0.0448, 0.0142, 0.4295, 0.6810,\n",
              "          0.1553, 0.3846],\n",
              "         [0.2566, 0.4107, 0.0300, 0.2207, 0.1135, 0.3881, 0.1383, 0.4295, 0.2414,\n",
              "          0.0497, 0.1231],\n",
              "         [0.3009, 0.3571, 0.0300, 0.0552, 0.0968, 0.1343, 0.0993, 0.4170, 0.5172,\n",
              "          0.1118, 0.2462],\n",
              "         [0.8142, 0.3304, 0.6700, 0.1448, 0.1352, 0.0746, 0.0284, 0.6263, 0.2414,\n",
              "          0.3354, 0.5538]]),\n",
              " tensor([6., 5., 6., 5., 5., 6., 6., 5., 5., 5., 6., 6., 5., 5., 5., 6., 5., 5.,\n",
              "         5., 5., 5., 5., 7., 8., 6., 4., 7., 4., 4., 5., 5., 6.])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4326d87617054a2bb0f8752371b65e0a",
            "a31306f8e12f4dd095096516e42917cb",
            "f5f220158b2c4a6b9b96987e6207551d",
            "f5d398181f6f441aafe826cb84a012a5",
            "4ed207055182460296f942157803da96",
            "94bfb3f3c4c14290a94964696f29f20e",
            "7d5092464c674b6db9860b83eb7235eb",
            "80eeefd1fda742e2bb6cf82d30dd597e"
          ]
        },
        "id": "fsdcYHJWJJTR",
        "outputId": "fc84c324-8535-458b-9c72-5defd53ff8d2"
      },
      "source": [
        "model = fit(model, criterion, optimizer, train_dl, val_dl, EPOCHS)"
      ],
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4326d87617054a2bb0f8752371b65e0a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=150.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1\n",
            "***************\n",
            "Train Loss: 30.1791\t Valid Loss: 27.6789\n",
            "Time per Epoch: 0.1579\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 2\n",
            "***************\n",
            "Train Loss: 23.0522\t Valid Loss: 15.6234\n",
            "Time per Epoch: 0.1482\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 3\n",
            "***************\n",
            "Train Loss: 6.4921\t Valid Loss: 0.8276\n",
            "Time per Epoch: 0.1358\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 4\n",
            "***************\n",
            "Train Loss: 0.9144\t Valid Loss: 0.7823\n",
            "Time per Epoch: 0.1405\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 5\n",
            "***************\n",
            "Train Loss: 0.7534\t Valid Loss: 0.7369\n",
            "Time per Epoch: 0.1259\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 6\n",
            "***************\n",
            "Train Loss: 0.7092\t Valid Loss: 0.7039\n",
            "Time per Epoch: 0.1528\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 7\n",
            "***************\n",
            "Train Loss: 0.6771\t Valid Loss: 0.6813\n",
            "Time per Epoch: 0.1215\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 8\n",
            "***************\n",
            "Train Loss: 0.6445\t Valid Loss: 0.6555\n",
            "Time per Epoch: 0.1406\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 9\n",
            "***************\n",
            "Train Loss: 0.6161\t Valid Loss: 0.6338\n",
            "Time per Epoch: 0.1238\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 10\n",
            "***************\n",
            "Train Loss: 0.5880\t Valid Loss: 0.6106\n",
            "Time per Epoch: 0.1599\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 11\n",
            "***************\n",
            "Train Loss: 0.5629\t Valid Loss: 0.5934\n",
            "Time per Epoch: 0.1590\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 12\n",
            "***************\n",
            "Train Loss: 0.5439\t Valid Loss: 0.5743\n",
            "Time per Epoch: 0.1327\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 13\n",
            "***************\n",
            "Train Loss: 0.5240\t Valid Loss: 0.5581\n",
            "Time per Epoch: 0.1313\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 14\n",
            "***************\n",
            "Train Loss: 0.5065\t Valid Loss: 0.5464\n",
            "Time per Epoch: 0.1362\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 15\n",
            "***************\n",
            "Train Loss: 0.4942\t Valid Loss: 0.5385\n",
            "Time per Epoch: 0.1321\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 16\n",
            "***************\n",
            "Train Loss: 0.4800\t Valid Loss: 0.5272\n",
            "Time per Epoch: 0.1566\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 17\n",
            "***************\n",
            "Train Loss: 0.4735\t Valid Loss: 0.5240\n",
            "Time per Epoch: 0.1545\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 18\n",
            "***************\n",
            "Train Loss: 0.4610\t Valid Loss: 0.5155\n",
            "Time per Epoch: 0.1471\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 19\n",
            "***************\n",
            "Train Loss: 0.4558\t Valid Loss: 0.5236\n",
            "Time per Epoch: 0.1596\n",
            "\n",
            "Epoch: 20\n",
            "***************\n",
            "Train Loss: 0.4526\t Valid Loss: 0.5509\n",
            "Time per Epoch: 0.1402\n",
            "\n",
            "Epoch: 21\n",
            "***************\n",
            "Train Loss: 0.4540\t Valid Loss: 0.5109\n",
            "Time per Epoch: 0.1209\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 22\n",
            "***************\n",
            "Train Loss: 0.4455\t Valid Loss: 0.5061\n",
            "Time per Epoch: 0.1368\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 23\n",
            "***************\n",
            "Train Loss: 0.4425\t Valid Loss: 0.5032\n",
            "Time per Epoch: 0.1391\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 24\n",
            "***************\n",
            "Train Loss: 0.4389\t Valid Loss: 0.5024\n",
            "Time per Epoch: 0.1322\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 25\n",
            "***************\n",
            "Train Loss: 0.4390\t Valid Loss: 0.5003\n",
            "Time per Epoch: 0.1243\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 26\n",
            "***************\n",
            "Train Loss: 0.4382\t Valid Loss: 0.5030\n",
            "Time per Epoch: 0.1519\n",
            "\n",
            "Epoch: 27\n",
            "***************\n",
            "Train Loss: 0.4312\t Valid Loss: 0.4999\n",
            "Time per Epoch: 0.1307\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 28\n",
            "***************\n",
            "Train Loss: 0.4313\t Valid Loss: 0.4974\n",
            "Time per Epoch: 0.1451\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 29\n",
            "***************\n",
            "Train Loss: 0.4294\t Valid Loss: 0.4984\n",
            "Time per Epoch: 0.1462\n",
            "\n",
            "Epoch: 30\n",
            "***************\n",
            "Train Loss: 0.4262\t Valid Loss: 0.4957\n",
            "Time per Epoch: 0.1286\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 31\n",
            "***************\n",
            "Train Loss: 0.4279\t Valid Loss: 0.5001\n",
            "Time per Epoch: 0.1287\n",
            "\n",
            "Epoch: 32\n",
            "***************\n",
            "Train Loss: 0.4299\t Valid Loss: 0.5028\n",
            "Time per Epoch: 0.1367\n",
            "\n",
            "Epoch: 33\n",
            "***************\n",
            "Train Loss: 0.4236\t Valid Loss: 0.4926\n",
            "Time per Epoch: 0.1418\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 34\n",
            "***************\n",
            "Train Loss: 0.4278\t Valid Loss: 0.5027\n",
            "Time per Epoch: 0.1352\n",
            "\n",
            "Epoch: 35\n",
            "***************\n",
            "Train Loss: 0.4281\t Valid Loss: 0.4942\n",
            "Time per Epoch: 0.1286\n",
            "\n",
            "Epoch: 36\n",
            "***************\n",
            "Train Loss: 0.4208\t Valid Loss: 0.4902\n",
            "Time per Epoch: 0.1299\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 37\n",
            "***************\n",
            "Train Loss: 0.4231\t Valid Loss: 0.4906\n",
            "Time per Epoch: 0.1380\n",
            "\n",
            "Epoch: 38\n",
            "***************\n",
            "Train Loss: 0.4178\t Valid Loss: 0.4898\n",
            "Time per Epoch: 0.1297\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 39\n",
            "***************\n",
            "Train Loss: 0.4193\t Valid Loss: 0.4884\n",
            "Time per Epoch: 0.1211\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 40\n",
            "***************\n",
            "Train Loss: 0.4270\t Valid Loss: 0.4889\n",
            "Time per Epoch: 0.1358\n",
            "\n",
            "Epoch: 41\n",
            "***************\n",
            "Train Loss: 0.4186\t Valid Loss: 0.4891\n",
            "Time per Epoch: 0.1389\n",
            "\n",
            "Epoch: 42\n",
            "***************\n",
            "Train Loss: 0.4182\t Valid Loss: 0.5019\n",
            "Time per Epoch: 0.1306\n",
            "\n",
            "Epoch: 43\n",
            "***************\n",
            "Train Loss: 0.4134\t Valid Loss: 0.4852\n",
            "Time per Epoch: 0.1232\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 44\n",
            "***************\n",
            "Train Loss: 0.4133\t Valid Loss: 0.4854\n",
            "Time per Epoch: 0.1511\n",
            "\n",
            "Epoch: 45\n",
            "***************\n",
            "Train Loss: 0.4104\t Valid Loss: 0.4872\n",
            "Time per Epoch: 0.1596\n",
            "\n",
            "Epoch: 46\n",
            "***************\n",
            "Train Loss: 0.4117\t Valid Loss: 0.4856\n",
            "Time per Epoch: 0.1306\n",
            "\n",
            "Epoch: 47\n",
            "***************\n",
            "Train Loss: 0.4119\t Valid Loss: 0.4920\n",
            "Time per Epoch: 0.1486\n",
            "\n",
            "Epoch: 48\n",
            "***************\n",
            "Train Loss: 0.4102\t Valid Loss: 0.4832\n",
            "Time per Epoch: 0.1498\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 49\n",
            "***************\n",
            "Train Loss: 0.4119\t Valid Loss: 0.4831\n",
            "Time per Epoch: 0.1281\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 50\n",
            "***************\n",
            "Train Loss: 0.4131\t Valid Loss: 0.4911\n",
            "Time per Epoch: 0.1330\n",
            "\n",
            "Epoch: 51\n",
            "***************\n",
            "Train Loss: 0.4064\t Valid Loss: 0.4822\n",
            "Time per Epoch: 0.1273\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 52\n",
            "***************\n",
            "Train Loss: 0.4079\t Valid Loss: 0.4854\n",
            "Time per Epoch: 0.1280\n",
            "\n",
            "Epoch: 53\n",
            "***************\n",
            "Train Loss: 0.4119\t Valid Loss: 0.4913\n",
            "Time per Epoch: 0.1345\n",
            "\n",
            "Epoch: 54\n",
            "***************\n",
            "Train Loss: 0.4068\t Valid Loss: 0.4922\n",
            "Time per Epoch: 0.1401\n",
            "\n",
            "Epoch: 55\n",
            "***************\n",
            "Train Loss: 0.4086\t Valid Loss: 0.4801\n",
            "Time per Epoch: 0.1413\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 56\n",
            "***************\n",
            "Train Loss: 0.4084\t Valid Loss: 0.4806\n",
            "Time per Epoch: 0.1326\n",
            "\n",
            "Epoch: 57\n",
            "***************\n",
            "Train Loss: 0.4109\t Valid Loss: 0.4939\n",
            "Time per Epoch: 0.1241\n",
            "\n",
            "Epoch: 58\n",
            "***************\n",
            "Train Loss: 0.4084\t Valid Loss: 0.4786\n",
            "Time per Epoch: 0.1399\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 59\n",
            "***************\n",
            "Train Loss: 0.4021\t Valid Loss: 0.4776\n",
            "Time per Epoch: 0.1294\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 60\n",
            "***************\n",
            "Train Loss: 0.4037\t Valid Loss: 0.4772\n",
            "Time per Epoch: 0.1291\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 61\n",
            "***************\n",
            "Train Loss: 0.4076\t Valid Loss: 0.4823\n",
            "Time per Epoch: 0.1327\n",
            "\n",
            "Epoch: 62\n",
            "***************\n",
            "Train Loss: 0.4008\t Valid Loss: 0.4762\n",
            "Time per Epoch: 0.1503\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 63\n",
            "***************\n",
            "Train Loss: 0.4028\t Valid Loss: 0.4766\n",
            "Time per Epoch: 0.1414\n",
            "\n",
            "Epoch: 64\n",
            "***************\n",
            "Train Loss: 0.4050\t Valid Loss: 0.4810\n",
            "Time per Epoch: 0.1276\n",
            "\n",
            "Epoch: 65\n",
            "***************\n",
            "Train Loss: 0.3969\t Valid Loss: 0.4971\n",
            "Time per Epoch: 0.1313\n",
            "\n",
            "Epoch: 66\n",
            "***************\n",
            "Train Loss: 0.4035\t Valid Loss: 0.4768\n",
            "Time per Epoch: 0.1382\n",
            "\n",
            "Epoch: 67\n",
            "***************\n",
            "Train Loss: 0.3989\t Valid Loss: 0.4791\n",
            "Time per Epoch: 0.1257\n",
            "\n",
            "Epoch: 68\n",
            "***************\n",
            "Train Loss: 0.3999\t Valid Loss: 0.5347\n",
            "Time per Epoch: 0.1456\n",
            "\n",
            "Epoch: 69\n",
            "***************\n",
            "Train Loss: 0.4186\t Valid Loss: 0.4844\n",
            "Time per Epoch: 0.1230\n",
            "\n",
            "Epoch: 70\n",
            "***************\n",
            "Train Loss: 0.3976\t Valid Loss: 0.4736\n",
            "Time per Epoch: 0.1430\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 71\n",
            "***************\n",
            "Train Loss: 0.3993\t Valid Loss: 0.4731\n",
            "Time per Epoch: 0.1301\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 72\n",
            "***************\n",
            "Train Loss: 0.4009\t Valid Loss: 0.4827\n",
            "Time per Epoch: 0.1429\n",
            "\n",
            "Epoch: 73\n",
            "***************\n",
            "Train Loss: 0.4062\t Valid Loss: 0.4725\n",
            "Time per Epoch: 0.1246\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 74\n",
            "***************\n",
            "Train Loss: 0.4031\t Valid Loss: 0.4845\n",
            "Time per Epoch: 0.1296\n",
            "\n",
            "Epoch: 75\n",
            "***************\n",
            "Train Loss: 0.4010\t Valid Loss: 0.4782\n",
            "Time per Epoch: 0.1403\n",
            "\n",
            "Epoch: 76\n",
            "***************\n",
            "Train Loss: 0.3969\t Valid Loss: 0.4758\n",
            "Time per Epoch: 0.1386\n",
            "\n",
            "Epoch: 77\n",
            "***************\n",
            "Train Loss: 0.3932\t Valid Loss: 0.4711\n",
            "Time per Epoch: 0.1264\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 78\n",
            "***************\n",
            "Train Loss: 0.3946\t Valid Loss: 0.4707\n",
            "Time per Epoch: 0.1455\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 79\n",
            "***************\n",
            "Train Loss: 0.3927\t Valid Loss: 0.4730\n",
            "Time per Epoch: 0.1332\n",
            "\n",
            "Epoch: 80\n",
            "***************\n",
            "Train Loss: 0.3947\t Valid Loss: 0.4725\n",
            "Time per Epoch: 0.1284\n",
            "\n",
            "Epoch: 81\n",
            "***************\n",
            "Train Loss: 0.3944\t Valid Loss: 0.4718\n",
            "Time per Epoch: 0.1258\n",
            "\n",
            "Epoch: 82\n",
            "***************\n",
            "Train Loss: 0.3929\t Valid Loss: 0.4723\n",
            "Time per Epoch: 0.1318\n",
            "\n",
            "Epoch: 83\n",
            "***************\n",
            "Train Loss: 0.3994\t Valid Loss: 0.4695\n",
            "Time per Epoch: 0.1267\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 84\n",
            "***************\n",
            "Train Loss: 0.3929\t Valid Loss: 0.4759\n",
            "Time per Epoch: 0.1455\n",
            "\n",
            "Epoch: 85\n",
            "***************\n",
            "Train Loss: 0.4025\t Valid Loss: 0.4715\n",
            "Time per Epoch: 0.1487\n",
            "\n",
            "Epoch: 86\n",
            "***************\n",
            "Train Loss: 0.3933\t Valid Loss: 0.4675\n",
            "Time per Epoch: 0.1423\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 87\n",
            "***************\n",
            "Train Loss: 0.3968\t Valid Loss: 0.4717\n",
            "Time per Epoch: 0.1266\n",
            "\n",
            "Epoch: 88\n",
            "***************\n",
            "Train Loss: 0.3880\t Valid Loss: 0.4742\n",
            "Time per Epoch: 0.1434\n",
            "\n",
            "Epoch: 89\n",
            "***************\n",
            "Train Loss: 0.3893\t Valid Loss: 0.4793\n",
            "Time per Epoch: 0.1520\n",
            "\n",
            "Epoch: 90\n",
            "***************\n",
            "Train Loss: 0.4054\t Valid Loss: 0.4763\n",
            "Time per Epoch: 0.1308\n",
            "\n",
            "Epoch: 91\n",
            "***************\n",
            "Train Loss: 0.3959\t Valid Loss: 0.4670\n",
            "Time per Epoch: 0.1258\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 92\n",
            "***************\n",
            "Train Loss: 0.3913\t Valid Loss: 0.4643\n",
            "Time per Epoch: 0.1836\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 93\n",
            "***************\n",
            "Train Loss: 0.3904\t Valid Loss: 0.4618\n",
            "Time per Epoch: 0.1406\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 94\n",
            "***************\n",
            "Train Loss: 0.3917\t Valid Loss: 0.4766\n",
            "Time per Epoch: 0.1352\n",
            "\n",
            "Epoch: 95\n",
            "***************\n",
            "Train Loss: 0.3899\t Valid Loss: 0.4717\n",
            "Time per Epoch: 0.1651\n",
            "\n",
            "Epoch: 96\n",
            "***************\n",
            "Train Loss: 0.3917\t Valid Loss: 0.4630\n",
            "Time per Epoch: 0.1288\n",
            "\n",
            "Epoch: 97\n",
            "***************\n",
            "Train Loss: 0.3901\t Valid Loss: 0.4645\n",
            "Time per Epoch: 0.1260\n",
            "\n",
            "Epoch: 98\n",
            "***************\n",
            "Train Loss: 0.3885\t Valid Loss: 0.4738\n",
            "Time per Epoch: 0.1376\n",
            "\n",
            "Epoch: 99\n",
            "***************\n",
            "Train Loss: 0.3948\t Valid Loss: 0.4753\n",
            "Time per Epoch: 0.1389\n",
            "\n",
            "Epoch: 100\n",
            "***************\n",
            "Train Loss: 0.3995\t Valid Loss: 0.4615\n",
            "Time per Epoch: 0.1894\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 101\n",
            "***************\n",
            "Train Loss: 0.3871\t Valid Loss: 0.4690\n",
            "Time per Epoch: 0.1724\n",
            "\n",
            "Epoch: 102\n",
            "***************\n",
            "Train Loss: 0.3878\t Valid Loss: 0.4662\n",
            "Time per Epoch: 0.1501\n",
            "\n",
            "Epoch: 103\n",
            "***************\n",
            "Train Loss: 0.3863\t Valid Loss: 0.4627\n",
            "Time per Epoch: 0.1220\n",
            "\n",
            "Epoch: 104\n",
            "***************\n",
            "Train Loss: 0.3810\t Valid Loss: 0.4594\n",
            "Time per Epoch: 0.1195\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 105\n",
            "***************\n",
            "Train Loss: 0.3854\t Valid Loss: 0.4621\n",
            "Time per Epoch: 0.1231\n",
            "\n",
            "Epoch: 106\n",
            "***************\n",
            "Train Loss: 0.3825\t Valid Loss: 0.4753\n",
            "Time per Epoch: 0.1467\n",
            "\n",
            "Epoch: 107\n",
            "***************\n",
            "Train Loss: 0.3859\t Valid Loss: 0.4609\n",
            "Time per Epoch: 0.1267\n",
            "\n",
            "Epoch: 108\n",
            "***************\n",
            "Train Loss: 0.3801\t Valid Loss: 0.4592\n",
            "Time per Epoch: 0.1401\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 109\n",
            "***************\n",
            "Train Loss: 0.3838\t Valid Loss: 0.4733\n",
            "Time per Epoch: 0.1388\n",
            "\n",
            "Epoch: 110\n",
            "***************\n",
            "Train Loss: 0.3864\t Valid Loss: 0.4599\n",
            "Time per Epoch: 0.1439\n",
            "\n",
            "Epoch: 111\n",
            "***************\n",
            "Train Loss: 0.3827\t Valid Loss: 0.4578\n",
            "Time per Epoch: 0.1271\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 112\n",
            "***************\n",
            "Train Loss: 0.3821\t Valid Loss: 0.4583\n",
            "Time per Epoch: 0.1445\n",
            "\n",
            "Epoch: 113\n",
            "***************\n",
            "Train Loss: 0.3793\t Valid Loss: 0.4573\n",
            "Time per Epoch: 0.1369\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 114\n",
            "***************\n",
            "Train Loss: 0.3805\t Valid Loss: 0.4626\n",
            "Time per Epoch: 0.1340\n",
            "\n",
            "Epoch: 115\n",
            "***************\n",
            "Train Loss: 0.3831\t Valid Loss: 0.4561\n",
            "Time per Epoch: 0.1271\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 116\n",
            "***************\n",
            "Train Loss: 0.3809\t Valid Loss: 0.4558\n",
            "Time per Epoch: 0.1364\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 117\n",
            "***************\n",
            "Train Loss: 0.3801\t Valid Loss: 0.4576\n",
            "Time per Epoch: 0.1290\n",
            "\n",
            "Epoch: 118\n",
            "***************\n",
            "Train Loss: 0.3849\t Valid Loss: 0.4550\n",
            "Time per Epoch: 0.1579\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 119\n",
            "***************\n",
            "Train Loss: 0.3792\t Valid Loss: 0.4599\n",
            "Time per Epoch: 0.1282\n",
            "\n",
            "Epoch: 120\n",
            "***************\n",
            "Train Loss: 0.3831\t Valid Loss: 0.4839\n",
            "Time per Epoch: 0.1371\n",
            "\n",
            "Epoch: 121\n",
            "***************\n",
            "Train Loss: 0.3844\t Valid Loss: 0.4543\n",
            "Time per Epoch: 0.1492\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 122\n",
            "***************\n",
            "Train Loss: 0.3787\t Valid Loss: 0.4551\n",
            "Time per Epoch: 0.1809\n",
            "\n",
            "Epoch: 123\n",
            "***************\n",
            "Train Loss: 0.3771\t Valid Loss: 0.4534\n",
            "Time per Epoch: 0.1676\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 124\n",
            "***************\n",
            "Train Loss: 0.3783\t Valid Loss: 0.4546\n",
            "Time per Epoch: 0.1267\n",
            "\n",
            "Epoch: 125\n",
            "***************\n",
            "Train Loss: 0.3795\t Valid Loss: 0.4526\n",
            "Time per Epoch: 0.1400\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 126\n",
            "***************\n",
            "Train Loss: 0.3807\t Valid Loss: 0.4919\n",
            "Time per Epoch: 0.1278\n",
            "\n",
            "Epoch: 127\n",
            "***************\n",
            "Train Loss: 0.3860\t Valid Loss: 0.4520\n",
            "Time per Epoch: 0.1286\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 128\n",
            "***************\n",
            "Train Loss: 0.3862\t Valid Loss: 0.4574\n",
            "Time per Epoch: 0.1405\n",
            "\n",
            "Epoch: 129\n",
            "***************\n",
            "Train Loss: 0.3776\t Valid Loss: 0.4569\n",
            "Time per Epoch: 0.1304\n",
            "\n",
            "Epoch: 130\n",
            "***************\n",
            "Train Loss: 0.3759\t Valid Loss: 0.4518\n",
            "Time per Epoch: 0.1358\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 131\n",
            "***************\n",
            "Train Loss: 0.3733\t Valid Loss: 0.4644\n",
            "Time per Epoch: 0.1402\n",
            "\n",
            "Epoch: 132\n",
            "***************\n",
            "Train Loss: 0.3735\t Valid Loss: 0.4513\n",
            "Time per Epoch: 0.1358\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 133\n",
            "***************\n",
            "Train Loss: 0.3753\t Valid Loss: 0.4512\n",
            "Time per Epoch: 0.1308\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 134\n",
            "***************\n",
            "Train Loss: 0.3841\t Valid Loss: 0.4502\n",
            "Time per Epoch: 0.1299\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 135\n",
            "***************\n",
            "Train Loss: 0.3710\t Valid Loss: 0.4614\n",
            "Time per Epoch: 0.1362\n",
            "\n",
            "Epoch: 136\n",
            "***************\n",
            "Train Loss: 0.3702\t Valid Loss: 0.4514\n",
            "Time per Epoch: 0.1403\n",
            "\n",
            "Epoch: 137\n",
            "***************\n",
            "Train Loss: 0.3784\t Valid Loss: 0.4492\n",
            "Time per Epoch: 0.1260\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 138\n",
            "***************\n",
            "Train Loss: 0.3717\t Valid Loss: 0.4479\n",
            "Time per Epoch: 0.1252\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 139\n",
            "***************\n",
            "Train Loss: 0.3736\t Valid Loss: 0.4490\n",
            "Time per Epoch: 0.1332\n",
            "\n",
            "Epoch: 140\n",
            "***************\n",
            "Train Loss: 0.3925\t Valid Loss: 0.4779\n",
            "Time per Epoch: 0.1400\n",
            "\n",
            "Epoch: 141\n",
            "***************\n",
            "Train Loss: 0.3781\t Valid Loss: 0.4623\n",
            "Time per Epoch: 0.1493\n",
            "\n",
            "Epoch: 142\n",
            "***************\n",
            "Train Loss: 0.3783\t Valid Loss: 0.4667\n",
            "Time per Epoch: 0.1430\n",
            "\n",
            "Epoch: 143\n",
            "***************\n",
            "Train Loss: 0.3801\t Valid Loss: 0.4450\n",
            "Time per Epoch: 0.1423\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 144\n",
            "***************\n",
            "Train Loss: 0.3721\t Valid Loss: 0.4643\n",
            "Time per Epoch: 0.1332\n",
            "\n",
            "Epoch: 145\n",
            "***************\n",
            "Train Loss: 0.3821\t Valid Loss: 0.4439\n",
            "Time per Epoch: 0.1336\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 146\n",
            "***************\n",
            "Train Loss: 0.3737\t Valid Loss: 0.4522\n",
            "Time per Epoch: 0.1432\n",
            "\n",
            "Epoch: 147\n",
            "***************\n",
            "Train Loss: 0.3698\t Valid Loss: 0.4507\n",
            "Time per Epoch: 0.1266\n",
            "\n",
            "Epoch: 148\n",
            "***************\n",
            "Train Loss: 0.3765\t Valid Loss: 0.4420\n",
            "Time per Epoch: 0.1348\n",
            "\n",
            "\n",
            "New Best Val Loss Found!\n",
            "Epoch: 149\n",
            "***************\n",
            "Train Loss: 0.3775\t Valid Loss: 0.4672\n",
            "Time per Epoch: 0.1284\n",
            "\n",
            "Epoch: 150\n",
            "***************\n",
            "Train Loss: 0.3686\t Valid Loss: 0.4434\n",
            "Time per Epoch: 0.1472\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Id-Yhf6NJO3V"
      },
      "source": [
        "def predict(model, test_dl):\n",
        "  \"\"\" Predict \"\"\"\n",
        "  model.eval()\n",
        "  predY_list = []\n",
        "  with torch.no_grad():\n",
        "    for X, y in test_dl:\n",
        "      X = X.to(device)\n",
        "      predY = model(X)\n",
        "      predY_list.append(predY.numpy())\n",
        "\n",
        "  return [arr.squeeze().tolist() for arr in predY_list]\n"
      ],
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dK4MqJ2POi_D"
      },
      "source": [
        "y_pred = predict(model, test_dl)"
      ],
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZ4U_BPIOln1",
        "outputId": "e5a03612-34fe-4a0a-fcf3-07e154cc5170"
      },
      "source": [
        "print(mean_squared_error(testY, y_pred))\n",
        "print(r2_score(testY, y_pred))"
      ],
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.40196190779184987\n",
            "0.37706732614133076\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FQqVVwHO8YG"
      },
      "source": [
        "r2_score?"
      ],
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5c40KIc_PB1u"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}